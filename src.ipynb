{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqMmI63mYuiW"
      },
      "source": [
        "# VERITAS AI\n",
        "\n",
        "An immersive Virtual AI program for ambitious high school students, founded and run by Harvard graduate students. For more information, see [Veritas AI](https://www.veritasai.com/).\n",
        "\n",
        "<p align=\"center\">\n",
        "    <a href=\"https://www.veritasai.com/\">\n",
        "        <img src=\"https://images.squarespace-cdn.com/content/v1/61e9374e0434354049a258f9/f89e8510-6098-4747-a89e-0cd34fe13376/Veritas_Fellowship+MP+White+copy+2.png\" width=\"400\" height=\"400\"/>\n",
        "    </a>\n",
        "</p>\n",
        "\n",
        "## Content: All Slides and Codes\n",
        "\n",
        "The links of the colabs for the code walkthrough of the first 8 weeks are listed below. **PLEASE DO NOT EDIT THE SCRIPT DIRECTLY. REMEMBER TO SAVE AS A COPY IF YOU WANT TO RUN THE CODE**\n",
        "\n",
        "Section | Name | Links\n",
        "--- | --- | ---\n",
        "1 | **Intro to Basic Python, Numpy, and Pandas** | [Code](https://colab.research.google.com/drive/1z-0Z852bFOUNYhve0wbsCcRJCZpCqcqp?usp=sharing)\n",
        "2 | **Exploratory Data Analysis** | [Code](https://colab.research.google.com/drive/1VaSC8CsBxAn5JcnN2I5g2YP1m9aWBBMO?usp=sharing)\n",
        "3 | **Basics in Linear Regression** | [Code](https://colab.research.google.com/drive/1HC4netVsOZT1BHjyUNcu8u8f1Etfoi2b?usp=sharing)\n",
        "4 | **Basics in Logistic Regression** | [Code](https://colab.research.google.com/drive/1lm5nv5ULZqJBklZJMyRonJGyk0sNjWGi?usp=sharing)\n",
        "5 | **Intro to Neural Networks** | [Code](https://colab.research.google.com/drive/1OGxD35fQxXdWNDwYGYpZcES5zgo6UvdO?usp=sharing)\n",
        "6 | **Intro to Convolutional Neural Networks** | [Code](https://colab.research.google.com/drive/1YAjTioD_wUuRIKhacUDpH2TC6HEOfV5u?usp=sharing)\n",
        "7 | **More in Deep Neural Networks** | [Code](https://colab.research.google.com/drive/1uM7CzWPLifgf16aVtJhWeOGN6A0guvlv?usp=sharing)\n",
        "8 | **Advanced Convolutional Neural Networks** | [Code](https://colab.research.google.com/drive/1duxfMW5sQbx91c0BJWiP2oSHVdtcbtND?usp=sharing)\n",
        "\n",
        "REMEMBER: **PLEASE DO NOT EDIT THE SCRIPT DIRECTLY. REMEMBER TO SAVE AS A COPY IF YOU WANT TO RUN THE CODE**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz5XqoFiMSHl"
      },
      "source": [
        "# Healthcare Investment\n",
        "\n",
        "![image](https://bestpractice.bmj.com/info/wp-content/uploads/2020/08/iStock-1194838627-scaled.jpg)\n",
        "\n",
        "The length of stay (LOS) is an important indicator of the efficiency of hospital management. Reduction in the number of inpatient days results in decreased risk of infection and medication side effects, improvement in the quality of treatment, and increased hospital profit with more efficient bed management. The purpose of this study was to determine which factors are associated with length of hospital stay, based on electronic health records, in order to manage hospital stay more efficiently.\n",
        "\n",
        "Given medical data about different countries from 1990-2018, let's try to predict a patient's average hospital stay.\n",
        "\n",
        "## Source\n",
        "\n",
        "This [paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5898738/) has done an intensive study hospital management, which could provide crucial knowledge of hospital stay and healthcare investment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW21olgs2qBp"
      },
      "source": [
        "## Define Research Question\n",
        "\n",
        "What question will you try to answer?\n",
        "- What factors relate to length of stay? What can we do to reduce it?\n",
        "\n",
        "What factors relate to length of stay?\n",
        "\n",
        "Write your project goal in the form of a question to help guide the steps that follow.\n",
        "\n",
        "## Data Review & Corresponding Questions\n",
        "- why does australia have so few hospital beds (less than 2 per hospital?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLGHF04wxFVZ"
      },
      "source": [
        "## Data Introduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "wf5uSFAxwu2E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTKe13xixJZ4"
      },
      "source": [
        "Notice that this requires you to download the data form this [link](https://drive.google.com/drive/folders/1A0kC_tBOCkiYdtijeX82VsDyvUwRKEM4?usp=sharing). Please download the data called *Healthcare_Investments_and_Hospital_Stay*. For more EDA, please refer to this notebook [here](https://www.kaggle.com/gcdatkin/predicting-length-of-hospital-stay).\n",
        "\n",
        "Once you download the *csv* format data set from the link above you can save it in your computer locally at a directory you desire. Please upload that data set onto the Colab environment by going to the menu bar on the left and click on the *folder* button to open the directory of the notebook. Please directly upload your dataset to this Colab environment and then use the path defined below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "R_wZ1R5Sw11C",
        "outputId": "0e40a977-89fc-4d12-fae8-625a6e75bcd9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location</th>\n",
              "      <th>Time</th>\n",
              "      <th>Hospital_Stay</th>\n",
              "      <th>MRI_Units</th>\n",
              "      <th>CT_Scanners</th>\n",
              "      <th>Hospital_Beds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AUS</td>\n",
              "      <td>1992</td>\n",
              "      <td>6.6</td>\n",
              "      <td>1.43</td>\n",
              "      <td>16.71</td>\n",
              "      <td>1.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AUS</td>\n",
              "      <td>1994</td>\n",
              "      <td>6.4</td>\n",
              "      <td>2.36</td>\n",
              "      <td>18.48</td>\n",
              "      <td>2.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AUS</td>\n",
              "      <td>1995</td>\n",
              "      <td>6.5</td>\n",
              "      <td>2.89</td>\n",
              "      <td>20.55</td>\n",
              "      <td>2.89</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Location  Time  Hospital_Stay  MRI_Units  CT_Scanners  Hospital_Beds\n",
              "0      AUS  1992            6.6       1.43        16.71           1.43\n",
              "1      AUS  1994            6.4       2.36        18.48           2.36\n",
              "2      AUS  1995            6.5       2.89        20.55           2.89"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = \"./assets/Healthcare_Investments_and_Hospital_Stay.csv\"\n",
        "data = pd.read_csv(path)\n",
        "data.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "4rJHWoo_w66v",
        "outputId": "b9b495c3-9390-4b79-d961-4080994ced8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AUS' 'AUT' 'BEL' 'CAN' 'CZE' 'DNK' 'FIN' 'FRA' 'DEU' 'GRC' 'HUN' 'IRL'\n",
            " 'ITA' 'JPN' 'KOR' 'LUX' 'NLD' 'NZL' 'POL' 'PRT' 'SVK' 'ESP' 'TUR' 'GBR'\n",
            " 'USA' 'EST' 'ISR' 'RUS' 'SVN' 'ISL' 'LVA' 'LTU']\n",
            "[1992 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006\n",
            " 2009 2010 2011 2012 2013 2014 2015 2016 2017 2007 2008 2018 1990 1991\n",
            " 1993]\n",
            "[ 6.6  6.4  6.5  6.2  6.1  6.   5.9  5.1  5.   4.9  4.8  4.7  4.2  4.1\n",
            "  9.5  8.3  8.2  7.8  7.6  7.4  7.3  7.2  6.9  6.8  6.7  6.3  8.   7.9\n",
            "  7.7  7.1  7.  10.2 10.   9.9  9.8  7.5 11.9 11.6 11.2 10.8  5.8  3.8\n",
            "  3.7  3.6  3.4  5.7  5.6  5.5  5.4 10.1  9.6  9.3  8.9  8.8  8.7  8.5\n",
            "  8.1  5.3  5.2  9.7  9.2  8.6 32.7 27.2 22.2 18.8 17.9 16.9 16.2 11.\n",
            " 10.6 10.4  8.4  4.4  4.   3.9 13.6 14.3 14.  13.7 13.5 13.2 12.9 12.2\n",
            " 11.5 11.4 11.3 10.3  9.4  9.1  9. ]\n",
            "[ 1.43  2.36  2.89  2.96  3.53  4.51  6.01  3.52  3.79  3.74  3.7   3.76\n",
            "  4.26  4.89  5.72  5.67  5.6   5.5  13.84 14.65 14.49 14.3  14.15  7.54\n",
            "  8.53  8.52 11.01 10.98 11.69 13.36 13.54 15.91 16.16 16.81 17.72 18.03\n",
            " 18.46 18.65 18.71 19.1  19.22 19.66 20.71 22.43 22.96 23.53  6.84  7.\n",
            "  6.97  7.11  7.53 10.36 10.65 10.69 10.62 10.84 11.78 11.71 11.65 11.6\n",
            " 11.64  0.69  0.78  0.99  1.05  1.21  1.37  1.84  4.19  4.71  4.92  5.74\n",
            "  6.17  6.75  7.91  8.26  8.87  8.89  9.52 10.02  0.19  0.39  0.58  0.68\n",
            "  0.97  1.66  3.13  4.37  5.01  6.3   6.86  6.95  7.42  7.41  8.34  9.44\n",
            " 10.35  5.43  8.56  9.09 10.18  1.8   2.19  2.38  2.76  3.34  4.31  5.66\n",
            "  6.61  9.1   9.85 10.99 12.5  13.04 13.96 14.68 15.19 15.32 15.73 20.23\n",
            " 21.61 22.06 23.25 25.91 25.48 27.05 27.38  1.18  1.51  1.65  1.83  2.4\n",
            "  3.17  3.85  4.78  5.19  5.48  6.06  6.43  6.96  7.51  8.65  9.4  10.86\n",
            " 12.56 13.55 14.21 14.77 14.32 15.96 17.51 18.48 18.97 19.89 21.39 23.6\n",
            " 25.15 27.04 28.86 28.66 28.92 30.5  33.63 34.49 34.71 13.38 16.51 18.1\n",
            " 19.86 22.93 22.42 21.91 22.07 22.86  0.1   0.29  0.77  1.36  1.46  1.47\n",
            "  1.76  1.96  2.26  2.57  2.58  2.78  2.79  3.    3.01  2.82  3.03  3.14\n",
            "  3.56  3.97  4.7   4.91  7.95  8.41  8.91 12.28 13.1  12.39 13.19 13.31\n",
            " 14.04 14.72 15.18 16.03  4.11  5.82  6.25  7.76  9.07 10.85 11.9  14.09\n",
            " 15.01 16.96 18.77 20.06 21.59 22.47 24.17 24.62 25.2  26.19 28.24 28.4\n",
            " 28.73 18.75 23.19 35.32 42.96 46.86 51.69 55.21  1.81  2.87  3.86  5.14\n",
            "  5.4   6.8   7.85  8.98 19.88 21.27 23.37 24.35 25.5  26.27 27.81 29.08\n",
            " 30.08  4.48 11.07 10.91 10.75 10.58 10.42 14.06 13.81 13.5  13.18 12.88\n",
            " 12.58 12.29 12.   11.74 11.51  0.87  1.78  2.49  6.2   6.56  7.83  7.63\n",
            " 10.4  10.95 12.22 11.82 11.49 12.87 12.51 12.8  13.02 13.06  3.72  8.76\n",
            "  9.62  9.76 10.57 11.18 11.12 11.26 13.3  13.89 13.64  2.02  1.94  2.7\n",
            "  2.94  4.83  5.49  6.78  6.6   7.87  7.93  9.22  5.8   8.92  9.28  2.05\n",
            "  4.28  4.47  5.77  6.13  7.04  6.29  6.65  8.3   8.85  9.02  9.56  9.55\n",
            " 11.98 13.76 15.34 15.51 15.85 16.09 16.38 17.2   0.88  1.48  2.2   2.91\n",
            "  5.84  8.68  9.27  9.58  9.86  9.81 10.15 10.55 11.24  6.21  4.99  4.54\n",
            "  5.    5.62  6.55  7.16  7.2   7.23 11.41 17.44 19.32 26.67 26.58 25.93\n",
            " 34.46 35.51 38.12 39.03 36.74 37.65  2.21  3.71  5.22  8.23  7.49  9.79\n",
            "  9.83 11.38 12.16 13.68 13.66 13.62  1.4   1.64  1.62  1.73  2.23  2.33\n",
            "  2.27  3.29  3.47  4.02  4.06  5.16  5.18  0.92  0.61  0.7   0.85  0.74\n",
            "  1.13  1.11  1.31  1.54  2.12  2.52  2.51  2.62  4.17  3.99  4.44  4.64\n",
            "  4.52  4.6   4.84  6.48  7.35  7.81  8.77  8.75  9.21 11.14 11.61 12.05\n",
            " 19.26 18.9  21.98 22.01 21.94 21.83 21.62 21.38 21.16 20.87 20.38 19.85\n",
            "  2.68  6.89  7.47  8.1  10.43 12.54 12.64 13.78 13.9  13.49  0.86  1.5\n",
            "  3.06  3.4   4.38  5.37  5.94 10.04 10.48 11.02 12.2  12.37 12.49]\n",
            "[ 16.71  18.48  20.55  21.95  23.34  24.18  25.52  26.28  29.05  34.37\n",
            "  40.57  45.65  51.54  56.72  39.14  43.07  44.32  50.5   53.66  56.06\n",
            "  59.54  63.    64.34  24.25  25.23  26.08  26.02  26.09  26.61  27.1\n",
            "  27.21  29.25  29.66  29.87  30.02  29.68  29.36  29.89  29.55  29.77\n",
            "  29.6   29.37  28.93  29.07  28.64  28.84  10.5   11.23  12.79  12.51\n",
            "  13.08  13.91  14.26  13.95  13.77  15.04  22.94  21.77  23.59  23.92\n",
            "  23.82  23.89   7.15   7.13   7.33   7.53   7.69   7.99   8.19   9.77\n",
            "  10.27  10.68  11.57  12.04  12.74  13.8   14.23  14.62  14.69  14.77\n",
            "  15.07  15.35   2.13   4.65   5.71   6.19   6.68   9.65  12.34  12.91\n",
            "  13.39  14.17  14.51  15.03  15.11  16.12  15.52  15.76  16.09  11.42\n",
            "  14.47  14.43   9.83  10.17  10.51  11.25  11.79  11.75  12.49  12.45\n",
            "  12.22  12.78  13.52  13.69  13.27  14.    14.15  14.68  14.81  16.45\n",
            "  20.42  21.07  21.34  21.8   21.7   21.42  21.53  24.2   24.51  16.5\n",
            "   6.64   7.24   7.01   7.37   7.62   8.07   8.78  10.02  10.37  10.32\n",
            "  10.84  11.08  11.82  12.53  13.49  14.49  15.32  16.57  16.95  17.36\n",
            "  17.68  24.61  25.19  27.06  27.55  28.71  29.51  29.12  29.73  31.15\n",
            "  31.24  32.32  33.48  34.01  33.72  35.34  35.09  35.17  35.13  25.48\n",
            "  26.68  29.33  31.05  32.73  33.14  33.41  33.65  34.61   1.93   2.99\n",
            "   3.09   3.86   4.16   4.55   4.95   4.57   4.97   5.08   5.68   5.99\n",
            "   6.3    6.52   6.83   7.14   7.25   7.26   7.07   7.18   7.3    7.32\n",
            "   7.66   7.88   8.31   8.43   8.86   9.19   9.41  12.63  14.09  14.99\n",
            "  15.72  16.74  17.73  16.53  17.65  17.24  19.14  20.34  14.8   18.01\n",
            "  18.99  21.13  23.01  24.05  26.23  27.82  29.29  30.55  30.96  31.85\n",
            "  32.17  32.62  33.29  33.1   32.9   33.31  34.29  34.57  35.12  74.7\n",
            "  84.41  92.62  96.97 101.25 107.17 111.49  15.5   20.12  21.02  28.38\n",
            "  27.3   30.94  31.86  35.79  36.93  37.5   36.85  37.03  37.8   38.18\n",
            "  38.56  24.65  26.57  27.95  27.51  27.08  26.6   26.12  25.64  25.08\n",
            "  24.48  22.08  21.57  17.56  17.14  16.77   7.29   9.03   7.12   8.21\n",
            "   8.38   7.81  10.22  12.52  10.92  11.54  13.34  13.75  13.04  13.48\n",
            "  14.22  12.31  12.44  14.64  15.63  15.51  15.43  16.66  17.88  17.96\n",
            "  16.79   7.94   9.23  10.86  12.4   14.38  13.61  15.4   17.09  17.16\n",
            "  17.33  16.88  18.14  25.94  26.18  27.56   9.12  10.24  11.35  12.28\n",
            "  13.76  13.37  14.1   15.    15.53  15.33  17.35  17.31  17.28  18.36\n",
            "  15.95  16.64  17.19  17.59  17.6   18.02  18.31  18.65  19.12   4.89\n",
            "   5.63   6.6    7.44   8.56   9.62  11.63  12.36  13.12  13.53  13.89\n",
            "  13.88  14.31  14.53  14.88   6.88   6.91   7.02   7.45   7.92   8.48\n",
            "   9.09   9.3    9.46  24.1   25.09  28.88  29.26  32.29  34.02  34.31\n",
            "  43.89  43.5   41.05  41.01  41.88  42.74   7.38   7.42  11.19  14.96\n",
            "  15.77  17.39  18.97  19.78  16.72  17.48  18.22  18.91   5.57   6.37\n",
            "   6.24   5.83   6.32   6.49   6.38   8.68   8.79   8.76   8.98   8.93\n",
            "   9.49   9.67   9.6    9.53   9.57   1.58   1.48   1.82   2.1    2.21\n",
            "   2.32   2.39   2.58   2.66   2.77   3.32   3.77   4.04   4.42   5.02\n",
            "   6.02   6.9    7.72  11.28  12.2   12.56  12.76  13.    10.46  12.37\n",
            "  11.77  12.69  12.67  12.64  12.14  13.09  14.04  15.91  32.1   31.5\n",
            "  34.54  37.73  40.75  40.53  40.15  39.71  39.3   38.76  43.68  48.2\n",
            "  13.55  15.02  21.81  23.88  25.68  29.08  31.07  32.44  34.78  36.11\n",
            "  36.91  36.23  39.13  38.4    6.57   7.2    8.71   9.08  11.55  12.84\n",
            "  10.52  18.73  20.14  23.76  23.67  22.17  21.    23.33  24.27]\n",
            "[ 1.43  2.36  2.89  2.96  3.53  4.51  6.01  3.52  3.79  3.74  3.7   3.76\n",
            "  4.26  4.89  5.72  5.67  5.6   5.5  13.84 14.65 14.49 14.3  14.15  7.54\n",
            "  8.53  8.52 11.01 10.98 11.69 13.36 13.54 15.91 16.16 16.81 17.72 18.03\n",
            " 18.46 18.65 18.71 19.1  19.22 19.66 20.71 22.43 22.96 23.53  6.84  7.\n",
            "  6.97  7.11  7.53 10.36 10.65 10.69 10.62 10.84 11.78 11.71 11.65 11.6\n",
            " 11.64  0.69  0.78  0.99  1.05  1.21  1.37  1.84  4.19  4.71  4.92  5.74\n",
            "  6.17  6.75  7.91  8.26  8.87  8.89  9.52 10.02  0.19  0.39  0.58  0.68\n",
            "  0.97  1.66  3.13  4.37  5.01  6.3   6.86  6.95  7.42  7.41  8.34  9.44\n",
            " 10.35  5.43  8.56  9.09 10.18  1.8   2.19  2.38  2.76  3.34  4.31  5.66\n",
            "  6.61  9.1   9.85 10.99 12.5  13.04 13.96 14.68 15.19 15.32 15.73 20.23\n",
            " 21.61 22.06 23.25 25.91 25.48 27.05 27.38  1.18  1.51  1.65  1.83  2.4\n",
            "  3.17  3.85  4.78  5.19  5.48  6.06  6.43  6.96  7.51  8.65  9.4  10.86\n",
            " 12.56 13.55 14.21 14.77 14.32 15.96 17.51 18.48 18.97 19.89 21.39 23.6\n",
            " 25.15 27.04 28.86 28.66 28.92 30.5  33.63 34.49 34.71 13.38 16.51 18.1\n",
            " 19.86 22.93 22.42 21.91 22.07 22.86  0.1   0.29  0.77  1.36  1.46  1.47\n",
            "  1.76  1.96  2.26  2.57  2.58  2.78  2.79  3.    3.01  2.82  3.03  3.14\n",
            "  3.56  3.97  4.7   4.91  7.95  8.41  8.91 12.28 13.1  12.39 13.19 13.31\n",
            " 14.04 14.72 15.18 16.03  4.11  5.82  6.25  7.76  9.07 10.85 11.9  14.09\n",
            " 15.01 16.96 18.77 20.06 21.59 22.47 24.17 24.62 25.2  26.19 28.24 28.4\n",
            " 28.73 18.75 23.19 35.32 42.96 46.86 51.69 55.21  1.81  2.87  3.86  5.14\n",
            "  5.4   6.8   7.85  8.98 19.88 21.27 23.37 24.35 25.5  26.27 27.81 29.08\n",
            " 30.08  4.48 11.07 10.91 10.75 10.58 10.42 14.06 13.81 13.5  13.18 12.88\n",
            " 12.58 12.29 12.   11.74 11.51  0.87  1.78  2.49  6.2   6.56  7.83  7.63\n",
            " 10.4  10.95 12.22 11.82 11.49 12.87 12.51 12.8  13.02 13.06  3.72  8.76\n",
            "  9.62  9.76 10.57 11.18 11.12 11.26 13.3  13.89 13.64  2.02  1.94  2.7\n",
            "  2.94  4.83  5.49  6.78  6.6   7.87  7.93  9.22  5.8   8.92  9.28  2.05\n",
            "  4.28  4.47  5.77  6.13  7.04  6.29  6.65  8.3   8.85  9.02  9.56  9.55\n",
            " 11.98 13.76 15.34 15.51 15.85 16.09 16.38 17.2   0.88  1.48  2.2   2.91\n",
            "  5.84  8.68  9.27  9.58  9.86  9.81 10.15 10.55 11.24  6.21  4.99  4.54\n",
            "  5.    5.62  6.55  7.16  7.2   7.23 11.41 17.44 19.32 26.67 26.58 25.93\n",
            " 34.46 35.51 38.12 39.03 36.74 37.65  2.21  3.71  5.22  8.23  7.49  9.79\n",
            "  9.83 11.38 12.16 13.68 13.66 13.62  1.4   1.64  1.62  1.73  2.23  2.33\n",
            "  2.27  3.29  3.47  4.02  4.06  5.16  5.18  0.92  0.61  0.7   0.85  0.74\n",
            "  1.13  1.11  1.31  1.54  2.12  2.52  2.51  2.62  4.17  3.99  4.44  4.64\n",
            "  4.52  4.6   4.84  6.48  7.35  7.81  8.77  8.75  9.21 11.14 11.61 12.05\n",
            " 19.26 18.9  21.98 22.01 21.94 21.83 21.62 21.38 21.16 20.87 20.38 19.85\n",
            "  2.68  6.89  7.47  8.1  10.43 12.54 12.64 13.78 13.9  13.49  0.86  1.5\n",
            "  3.06  3.4   4.38  5.37  5.94 10.04 10.48 11.02 12.2  12.37 12.49]\n"
          ]
        }
      ],
      "source": [
        "data.describe()\n",
        "\n",
        "for feature in data.columns:\n",
        "    print(data[feature].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk4N3yLQw7uH",
        "outputId": "adf5e0cd-94e2-4dff-f024-6d73bc64fd03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 518 entries, 0 to 517\n",
            "Data columns (total 6 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Location       518 non-null    object \n",
            " 1   Time           518 non-null    int64  \n",
            " 2   Hospital_Stay  518 non-null    float64\n",
            " 3   MRI_Units      518 non-null    float64\n",
            " 4   CT_Scanners    518 non-null    float64\n",
            " 5   Hospital_Beds  518 non-null    float64\n",
            "dtypes: float64(4), int64(1), object(1)\n",
            "memory usage: 24.4+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4JJzdJsw_Pi",
        "outputId": "e9dfb728-ac0c-4791-9d50-95520c08b849"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Location', 'Time', 'Hospital_Stay', 'MRI_Units', 'CT_Scanners',\n",
              "       'Hospital_Beds'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4Y_DEqU2n9l"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "Exploratory Data Analysis (EDA) is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us before the formal modeling or hypothesis testing task.\n",
        "\n",
        "\n",
        "You can refer to more resources here in this [code](https://colab.research.google.com/drive/1KkG1V7RsnKjCRd0zx0h434nqiXwOf-fG?authuser=1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU0dB8z5QZOe"
      },
      "source": [
        "1) Find the shape of your training and testing datasets (Hint: use the shape() function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "e1pgHO8LRaNQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Your code here\n",
        "features, labels = data.drop(columns=['Location', 'Hospital_Stay']), data['Hospital_Stay']\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "features = scaler.fit_transform(features)\n",
        "features = pd.DataFrame(features, columns = data.drop(['Location', \"Hospital_Stay\"], axis = 1).columns)\n",
        "\n",
        "\n",
        "# features.shape, labels.shape\n",
        "# features\n",
        "# labels\n",
        "trainX, testX, trainY, testY = train_test_split(features, labels, test_size=.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orw3J1VaRcRy"
      },
      "source": [
        "2) Plot a histogram of one of the columns you find interesting in the data frame. (Hint: Recall the *.hist()* method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "CUQnYrg0R8sv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Your code here\n",
        "import matplotlib\n",
        "\n",
        "features['Hospital_Beds'].hist()\n",
        "# for feat in features.columns:\n",
        "#     features[feat].hist()\n",
        "#     print(1/0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgjaQhLFR-Hw"
      },
      "source": [
        "3) Plot a scatter plot of two columns that you find interesting in the data frame. (Hint: Recall in *matplotlib.pyplot* there is the *.scatter* method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "UGmhISniSV0o"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Your code here\n",
        "import matplotlib.pyplot as plt\n",
        "for feature in ['MRI_Units', 'CT_Scanners']:\n",
        "    plt.scatter(features[feature], labels)\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Length of Stay')\n",
        "    plt.savefig('%s.png' % feature)\n",
        "    plt.clf()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZS4UzRWSbFR"
      },
      "source": [
        "4) Try to think of one more step on your own here. What else would you like to know about the data or how it is arranged?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "HAk-kXQ4SpE4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.2506313180685615"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code here\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
        "\n",
        "def trainLinearRegressor(trainX, trainY):\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(trainX, trainY)\n",
        "    return lr\n",
        "\n",
        "lr = trainLinearRegressor(trainX, trainY)\n",
        "preds = lr.predict(testX)\n",
        "mean_squared_error(testY, preds)\n",
        "root_mean_squared_error(testY, preds)\n",
        "\n",
        "# testX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Time', 'MRI_Units', 'CT_Scanners', 'Hospital_Beds'], dtype='object') Index(['Time', 'MRI_Units', 'CT_Scanners', 'Hospital_Beds'], dtype='object')\n",
            "Epoch 1/150\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Could not interpret metric identifier: error",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[58], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m     nn\u001b[38;5;241m.\u001b[39mfit(trainX, trainY, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,\n\u001b[1;32m     18\u001b[0m            validation_data\u001b[38;5;241m=\u001b[39m[testX, testY])\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nn\n\u001b[0;32m---> 22\u001b[0m nn \u001b[38;5;241m=\u001b[39m \u001b[43mtrainNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestY\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[58], line 17\u001b[0m, in \u001b[0;36mtrainNN\u001b[0;34m(trainX, trainY, testX, testY)\u001b[0m\n\u001b[1;32m      5\u001b[0m nn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      6\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m      7\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m ])\n\u001b[1;32m     13\u001b[0m nn\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     14\u001b[0m            loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m            metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 17\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m       \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtestX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestY\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nn\n",
            "File \u001b[0;32m~/workspace/veritas/project/lengthOfStay/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/workspace/veritas/project/lengthOfStay/env/lib/python3.10/site-packages/keras/src/metrics/__init__.py:206\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret metric identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: Could not interpret metric identifier: error"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(trainX.columns, testX.columns)\n",
        "# trainX, testX = trainX.drop(columns=['Location']), testX.drop(columns=['Location'])\n",
        "def trainNN(trainX, trainY, testX, testY):\n",
        "    nn = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(4),\n",
        "        tf.keras.layers.Dense(4),\n",
        "        tf.keras.layers.Dense(4),\n",
        "        tf.keras.layers.Dense(4),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    nn.compile(optimizer = \"adam\", \n",
        "               loss = \"mean_squared_error\",\n",
        "               metrics=['accuracy'])\n",
        "    \n",
        "    nn.fit(trainX, trainY, epochs=150,\n",
        "           validation_data=[testX, testY])\n",
        "    \n",
        "    return nn\n",
        "\n",
        "nn = trainNN(trainX, trainY, testX, testY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.2542141177552453"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "predictions = [float(x) for x in nn(testX)]\n",
        "\n",
        "root_mean_squared_error(testY, predictions)\n",
        "# print(list(zip(predictions, testY)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1HOXgQ02jZq"
      },
      "source": [
        "## Baseline Model\n",
        "\n",
        "Fundamentally, a baseline is a model that is both simple to set up and has a reasonable chance of providing decent results. Experimenting with them is usually quick and low cost, since implementations are widely available in popular packages.\n",
        "\n",
        "# To do:\n",
        "\n",
        "1) Separate training and testing sets\n",
        "\n",
        "2) Create a traditional neural network model for classification. Code examples are [here](https://colab.research.google.com/drive/1OGxD35fQxXdWNDwYGYpZcES5zgo6UvdO?authuser=1) for reference.\n",
        "\n",
        "3) Plot your training and testing accuracy across epochs\n",
        "\n",
        "\n",
        "## Challenge:\n",
        "\n",
        "- Create another neural net with a different layer configuration. Does it improve performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM3C4Cr82--9"
      },
      "source": [
        "## Advanced Model\n",
        "\n",
        "With the knowledge from the baseline model, your team and the instructor can work together to develop advanced models. Advanced models can have the following impact:\n",
        "\n",
        "- higher accuracy (we usually refer to test set performance and advanced models should have higher performance in the test set than baseline models)\n",
        "- auto-tune (some advanced model can be due to more automatic tuning procedure, this means the advanced model is a function instead of a fixed model)\n",
        "\n",
        "Examples:\n",
        "- Build a model that is more complex or can improve upon your predictions for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2cZEJLu3AUs"
      },
      "source": [
        "## Model Tuning\n",
        "\n",
        "Recall in Week 5, we discussed hyperparameters tuning. You can refer to this code [here](https://colab.research.google.com/drive/1BdW6zSQ2XAUcLI83CANcFBQaBw5WgepK)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtFRFzlN3Ckl"
      },
      "source": [
        "## Performance Summary\n",
        "\n",
        "Make a presentation of your result. You can refer to the syntax below.\n",
        "\n",
        "Markdown | Preview\n",
        "--- | ---\n",
        "`**Model 1**` | **Model 2**\n",
        "`*70%*` or `_italicized text_` | *90%*\n",
        "`` `Monospace` `` | `Monospace`\n",
        "`~~strikethrough~~` | ~~strikethrough~~\n",
        "`[A link](https://www.google.com)` | [A link](https://www.google.com)\n",
        "`![An image](https://www.google.com/images/rss.png)` | ![An image](https://www.google.com/images/rss.png)\n",
        "\n",
        "More resources about creating tables in markdown of colab can be found [here](https://colab.research.google.com/notebooks/markdown_guide.ipynb#scrollTo=Lhfnlq1Surtk)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub66k20i3Eys"
      },
      "source": [
        "## Interpretation and Future Work\n",
        "\n",
        "Present and also interpret your experimental performance. Comment on potential future work or research questions that your project leads to."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
